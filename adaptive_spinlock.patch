diff --git a/Python/lock.c b/Python/lock.c
index 1234567..abcdefg 100644
--- a/Python/lock.c
+++ b/Python/lock.c
@@ -20,11 +20,31 @@
 // starvation.
 static const PyTime_t TIME_TO_BE_FAIR_NS = 1000*1000;
 
-// Spin for a bit before parking the thread. This is only enabled for
-// `--disable-gil` builds because it is unlikely to be helpful if the GIL is
-// enabled.
+// Adaptive spinning data structure
+typedef struct {
+    _Py_atomic_int recent_contention;  // Recent contention count
+    int last_spin_count;               // Last used spin count
+} SpinAdaptiveData;
+
+// Thread-local adaptive spinning data
+static _Thread_local SpinAdaptiveData spin_data = {0, 40};
+
+// Get adaptive spin count based on recent contention
+static inline int get_adaptive_spin_count(void) {
 #if Py_GIL_DISABLED
-static const int MAX_SPIN_COUNT = 40;
+    int contention = _Py_atomic_load_int(&spin_data.recent_contention);
+    
+    // Simple three-tier adjustment
+    if (contention < 5) {
+        return 20;  // Low contention: less spinning
+    } else if (contention < 20) {
+        return 40;  // Medium contention: moderate spinning
+    } else {
+        return 60;  // High contention: more spinning
+    }
 #else
-static const int MAX_SPIN_COUNT = 0;
+    return 0;  // No spinning when GIL is enabled
 #endif
+}
 
 struct mutex_entry {
@@ -56,6 +76,11 @@ _PyMutex_LockTimed(PyMutex *m, PyTime_t timeout, _PyLockFlags flags)
     uint8_t v = _Py_atomic_load_uint8_relaxed(&m->_bits);
     if ((v & _Py_LOCKED) == 0) {
         if (_Py_atomic_compare_exchange_uint8(&m->_bits, &v, v|_Py_LOCKED)) {
+            // Successfully acquired, reduce contention count
+            int contention = _Py_atomic_load_int(&spin_data.recent_contention);
+            if (contention > 0) {
+                _Py_atomic_add_int(&spin_data.recent_contention, -1);
+            }
             return PY_LOCK_ACQUIRED;
         }
     }
@@ -75,6 +100,7 @@ _PyMutex_LockTimed(PyMutex *m, PyTime_t timeout, _PyLockFlags flags)
         .handed_off = 0,
     };
 
+    int max_spin = get_adaptive_spin_count();
     Py_ssize_t spin_count = 0;
     for (;;) {
         if ((v & _Py_LOCKED) == 0) {
@@ -85,12 +111,17 @@ _PyMutex_LockTimed(PyMutex *m, PyTime_t timeout, _PyLockFlags flags)
             continue;
         }
 
-        if (!(v & _Py_HAS_PARKED) && spin_count < MAX_SPIN_COUNT) {
+        if (!(v & _Py_HAS_PARKED) && spin_count < max_spin) {
             // Spin for a bit.
             _Py_yield();
             spin_count++;
             continue;
         }
+        
+        // Spinning failed, increase contention count
+        if (spin_count >= max_spin && max_spin > 0) {
+            _Py_atomic_add_int(&spin_data.recent_contention, 1);
+        }
 
         if (timeout == 0) {
             return PY_LOCK_FAILURE;